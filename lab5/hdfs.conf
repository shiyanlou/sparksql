a2.sources = r2
a2.channels = c2
a2.sinks = k2

#define sources
a2.sources.r2.type = exec      
a2.sources.r2.command =tail -F /home/hadoop/data/hdfs.log

#define channels
a2.channels.c2.type = memory
a2.channels.c2.capacity = 1000
a2.channels.c2.transactionCapacity = 100

#define sink
a2.sinks.k2.type = hdfs
a2.sinks.k2.hdfs.path = hdfs://localhost:9000/user/flume/data
a2.sinks.k2.hdfs.batchSize = 10
a2.sinks.k2.hdfs.fileType = DataStream
a2.sinks.k2.hdfs.writeFormat = Text 
a2.sinks.k2.hdfs.useLocalTimeStamp = true

#bind sources and sink to channel 
a2.sources.r2.channels = c2
a2.sinks.k2.channel = c2